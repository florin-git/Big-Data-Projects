{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import nltk\n",
    "\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import string\n",
    "import pickle\n",
    "import itertools\n",
    "from typing import *\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility\n",
    "SEED = 10\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Display the entire text\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: I tested my code in **local**, therefore it might happen that some result is different in Colab, even with the same random seed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Pre-processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is the [Amazon Fine Food Reviews](https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews). I only used the textual information from the reviews to compute the similarity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"./datasets/reviews.csv\"\n",
    "# Create a Pandas DataFrame\n",
    "df = pd.read_csv(dataset_path, sep = ',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get only the text from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = df['Text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By applying multiple times the method `sample` we can notice that the dataset is pretty 'dirty', as it contains HTML tags, URLS, non-english characters etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160375                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Very good for digestive system. Easy to eat with cold milk. Very flaky. Has a nice taste and texture. Sometimes hard to find in stores and the prices are high. You cannot beat the price if you buy from amazon.\n",
       "92654     I am a label reader - I count fat grams, carbs, proteins and grams of fiber vs. grams of sugar. Most foods that advertise themselves as a \"healthy\" snack are not really all that good for you. Often they are too high in calories or they use products that you just shouldn't eat. This snack food, FoodShouldTasteGood Multigrain chips really is a good tasting, good for you snack.<br /><br />The ingredients are listed on this page and you can see that there are no hydrogenated oils, no high fructose corn syrup and no MSG. They contain grains that are visible in the chip and a one ounce serving gives you 3 grams of fiber. (The packaging doesn't specify if it is soluble or insoluble.)<br /><br />The chips are delicious. They are thicker than what you would expect in a normal corn tortilla chip; more like a cracker in thickness but with the crunch of a chip. The flavor is similar to a popular name brand corn chip (Fritos) only without the added fat. I can see where some people say they have a stale taste - there is a grain that has a mild nutty flavor in the chip that you don't expect to taste in a corn chip. I recommend the multigrain chip if you are hungry for a salty snack that won't blow your diet and that leaves all the unhealthy junk out. I tried the Buffalo flavor and they have a very mild kick; much milder than I expected. I still like them, but not as much as the plain.  I really enjoy eating the Multigrain with a little lowfat queso!\n",
       "367563                                                                                                                                                                                                                                                                                                                                                                                                                               Before I get rambling, I have to say this stuff smells FANTASTIC, Crazy or not, occasionally I'll just open the jar and take a nice inhale.<br /><br />I bought this for two reasons, 1 my dog and I have been fighting the ups and downs of skin treatments for years. Antibiotics, skin creams, food changes, special shampoos, ugh you name it, I've put more money onto my dogs rear end then I have ever spent on myself, and to top it off all his skin issues make him smelly! I read online that coconut oil helps solve a multitude of issues inside and out, and since it's something all natural, I feel better about using it in general.<br /><br />I put it directly onto his legs and lower back just today, the fragrant coconut oil really helps with cutting back on how smelly he is, He seems less restless with his itchy spots - but only time will really tell if this stuff is really going to make any progress for him.<br /><br />The other reason I purchased this was because I wanted to make my own handmade soap, and it worked just fine for that use!\n",
       "557346                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Jolly Ranchers Watermellon hard candy from Amazon seller at $6+ are an excellent value. They are fresh and taste awesome...Believe the Seller is Alldirect?. Anyways, value, price, and service are spectacular for a tasty treat.<br /><br />yancyd\n",
       "143941                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                These are much better then I thought they would taste.  They have a good crunch and are true to graham flavor with a hint of saltiness.  My son really likes to snack on these, and I think they are better then the Earth's Best graham sticks I used to buy for him.  I stole a bag of these from our pantry and tried dipping them in nutella on the ends.  Heaven!\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the cleaning process, it is important to convert contractions in their extended form in order to reduce the vocabulary dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions_dict = {\n",
    "  \"ain't\": \"am not\",\n",
    "  \"aren't\": \"are not\",\n",
    "  \"can't\": \"cannot\",\n",
    "  \"can't've\": \"cannot have\",\n",
    "  \"'cause\": \"because\",\n",
    "  \"could've\": \"could have\",\n",
    "  \"couldn't\": \"could not\",\n",
    "  \"couldn't've\": \"could not have\",\n",
    "  \"didn't\": \"did not\",\n",
    "  \"doesn't\": \"does not\",\n",
    "  \"don't\": \"do not\",\n",
    "  \"hadn't\": \"had not\",\n",
    "  \"hadn't've\": \"had not have\",\n",
    "  \"hasn't\": \"has not\",\n",
    "  \"haven't\": \"have not\",\n",
    "  \"he'd\": \"he would\",\n",
    "  \"he'd've\": \"he would have\",\n",
    "  \"he'll\": \"he will\",\n",
    "  \"he'll've\": \"he will have\",\n",
    "  \"he's\": \"he is\",\n",
    "  \"how'd\": \"how did\",\n",
    "  \"how'd'y\": \"how do you\",\n",
    "  \"how'll\": \"how will\",\n",
    "  \"how's\": \"how is\",\n",
    "  \"i'd\": \"I would\",\n",
    "  \"i'd've\": \"I would have\",\n",
    "  \"i'll\": \"I will\",\n",
    "  \"i'll've\": \"I will have\",\n",
    "  \"i'm\": \"I am\",\n",
    "  \"i've\": \"I have\",\n",
    "  \"isn't\": \"is not\",\n",
    "  \"it'd\": \"it had\",\n",
    "  \"it'd've\": \"it would have\",\n",
    "  \"it'll\": \"it will\",\n",
    "  \"it'll've\": \"it will have\",\n",
    "  \"it's\": \"it is\",\n",
    "  \"let's\": \"let us\",\n",
    "  \"ma'am\": \"madam\",\n",
    "  \"mayn't\": \"may not\",\n",
    "  \"might've\": \"might have\",\n",
    "  \"mightn't\": \"might not\",\n",
    "  \"mightn't've\": \"might not have\",\n",
    "  \"must've\": \"must have\",\n",
    "  \"mustn't\": \"must not\",\n",
    "  \"mustn't've\": \"must not have\",\n",
    "  \"needn't\": \"need not\",\n",
    "  \"needn't've\": \"need not have\",\n",
    "  \"o'clock\": \"of the clock\",\n",
    "  \"oughtn't\": \"ought not\",\n",
    "  \"oughtn't've\": \"ought not have\",\n",
    "  \"shan't\": \"shall not\",\n",
    "  \"sha'n't\": \"shall not\",\n",
    "  \"shan't've\": \"shall not have\",\n",
    "  \"she'd\": \"she would\",\n",
    "  \"she'd've\": \"she would have\",\n",
    "  \"she'll\": \"she will\",\n",
    "  \"she'll've\": \"she will have\",\n",
    "  \"she's\": \"she is\",\n",
    "  \"should've\": \"should have\",\n",
    "  \"shouldn't\": \"should not\",\n",
    "  \"shouldn't've\": \"should not have\",\n",
    "  \"so've\": \"so have\",\n",
    "  \"so's\": \"so is\",\n",
    "  \"that'd\": \"that would\",\n",
    "  \"that'd've\": \"that would have\",\n",
    "  \"that's\": \"that is\",\n",
    "  \"there'd\": \"there had\",\n",
    "  \"there'd've\": \"there would have\",\n",
    "  \"there's\": \"there is\",\n",
    "  \"they'd\": \"they would\",\n",
    "  \"they'd've\": \"they would have\",\n",
    "  \"they'll\": \"they will\",\n",
    "  \"they'll've\": \"they will have\",\n",
    "  \"they're\": \"they are\",\n",
    "  \"they've\": \"they have\",\n",
    "  \"to've\": \"to have\",\n",
    "  \"wasn't\": \"was not\",\n",
    "  \"we'd\": \"we had\",\n",
    "  \"we'd've\": \"we would have\",\n",
    "  \"we'll\": \"we will\",\n",
    "  \"we'll've\": \"we will have\",\n",
    "  \"we're\": \"we are\",\n",
    "  \"we've\": \"we have\",\n",
    "  \"weren't\": \"were not\",\n",
    "  \"what'll\": \"what will\",\n",
    "  \"what'll've\": \"what will have\",\n",
    "  \"what're\": \"what are\",\n",
    "  \"what's\": \"what is\",\n",
    "  \"what've\": \"what have\",\n",
    "  \"when's\": \"when is\",\n",
    "  \"when've\": \"when have\",\n",
    "  \"where'd\": \"where did\",\n",
    "  \"where's\": \"where is\",\n",
    "  \"where've\": \"where have\",\n",
    "  \"who'll\": \"who will\",\n",
    "  \"who'll've\": \"who will have\",\n",
    "  \"who's\": \"who is\",\n",
    "  \"who've\": \"who have\",\n",
    "  \"why's\": \"why is\",\n",
    "  \"why've\": \"why have\",\n",
    "  \"will've\": \"will have\",\n",
    "  \"won't\": \"will not\",\n",
    "  \"won't've\": \"will not have\",\n",
    "  \"would've\": \"would have\",\n",
    "  \"wouldn't\": \"would not\",\n",
    "  \"wouldn't've\": \"would not have\",\n",
    "  \"y'all\": \"you all\",\n",
    "  \"y'alls\": \"you alls\",\n",
    "  \"y'all'd\": \"you all would\",\n",
    "  \"y'all'd've\": \"you all would have\",\n",
    "  \"y'all're\": \"you all are\",\n",
    "  \"y'all've\": \"you all have\",\n",
    "  \"you'd\": \"you had\",\n",
    "  \"you'd've\": \"you would have\",\n",
    "  \"you'll\": \"you will\",\n",
    "  \"you'll've\": \"you will have\",\n",
    "  \"you're\": \"you are\",\n",
    "  \"you've\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "class TextCleaner:\n",
    "    def __init__(self, df_text: pd.DataFrame, contractions_dict: Optional[ Dict[str, str] ] = None):\n",
    "        self.df_text = df_text\n",
    "\n",
    "        # Contractions\n",
    "        self.contractions_dict = contractions_dict\n",
    "\n",
    "        # URL pattern\n",
    "        self.url_pattern = re.compile(\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\")\n",
    "        self.htlm_pattern = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "\n",
    "        # Emoji pattern\n",
    "        self.emoji_pattern = re.compile(\"[\"\n",
    "                                u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                                u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                                u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                                u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                                u\"\\U00002702-\\U000027B0\"\n",
    "                                u\"\\U000024C2-\\U0001F251\"\n",
    "                                \"]+\", flags=re.UNICODE)\n",
    "\n",
    "        # Punctuation\n",
    "                                    # The last two dashes seem the same but actually the are not.\n",
    "        self.punctuation = list(string.punctuation) + [\"‘\",\"’\", \"“\", \"”\", \"–\", \"―\", \"—\"]\n",
    "\n",
    "        # Stopwords\n",
    "        self.stop_words = nltk.corpus.stopwords.words('english') \n",
    "        \n",
    "\n",
    "    def clean_df(self, do_lemmatization):\n",
    "        df_text_clean = self.df_text.apply(self.clean_text, args=(do_lemmatization,) )    \n",
    "        return df_text_clean\n",
    "\n",
    "    def clean_text (\n",
    "        self,\n",
    "        text: str, \n",
    "        do_lemmatization: bool = False,\n",
    "        do_stemming: bool = False,\n",
    "    ) -> str:\n",
    "\n",
    "        \"\"\"\n",
    "        Returns\n",
    "        -------\n",
    "            A 'cleaned' string, where are removed HTML, URLS, emoji, \n",
    "            punctuation, stopword and numbers. It can also be\n",
    "            lemmatized or stemmed.\n",
    "            \n",
    "        Parameters\n",
    "        ----------\n",
    "        text: str\n",
    "            The string to be cleaned. In this case, a sentence from the dataset.\n",
    "        \n",
    "        do_lemmatization: bool\n",
    "            If True the text is also lemmatize.\n",
    "        \n",
    "        do_stemming: bool\n",
    "            If True the text is also stemmatize.    \n",
    "        \"\"\"\n",
    "\n",
    "        text = str(text).lower()\n",
    "        \n",
    "        # Remove HTML\n",
    "        text = self.htlm_pattern.sub(r'', text)\n",
    "        text = self.url_pattern.sub(r'', text)\n",
    "        \n",
    "        # Remove Emoji\n",
    "        text = self.emoji_pattern.sub(r'', text)\n",
    "        \n",
    "        # Remove contractions\n",
    "        if contractions_dict is not None:\n",
    "            text = ' '.join([contractions_dict[token] if token in self.contractions_dict else token for token in text.split()])\n",
    "        \n",
    "        # Remove punctuation\n",
    "        text = ''.join([punc for punc in text if punc not in self.punctuation])\n",
    "        \n",
    "        # Remove stopwords\n",
    "        text = ' '.join([word for word in text.split() if word not in self.stop_words])\n",
    "\n",
    "        # Remove numbers\n",
    "        text = re.sub(\"\\d+\", \"\", text)\n",
    "\n",
    "        # Lemming\n",
    "        if do_lemmatization:\n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            text_lemmatize = [lemmatizer.lemmatize(token) for token in text.split()]\n",
    "            text = ' '.join(text_lemmatize)\n",
    "\n",
    "        # Stemming: e.g., history --> histori, historical --> histori\n",
    "        if do_stemming:\n",
    "            stemmer = PorterStemmer() \n",
    "            text_stemmed = [stemmer.stem(word) for word in text.split()]\n",
    "            text = ' '.join(text_stemmed)\n",
    "\n",
    "        # Remove strings with one or two characters only\n",
    "        text = ' '.join([l for l in text.split() if len(l) >= 3])\n",
    "\n",
    "        return text.strip() # Remove all the useless space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cleaner = TextCleaner(df_text, contractions_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_cleaned = text_cleaner.clean_df(do_lemmatization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_cleaned_text = \"./datasets/cleaned_text.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to save the cleaned dataset to disk, to avoid the cleaning operation to be executed every time.\n",
    "\n",
    "You can directly import the dataset from the next cell.\n",
    "\n",
    "    df_text_cleaned.to_csv(path_or_buf=path_cleaned_text, index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_cleaned = pd.read_csv(path_cleaned_text, sep = ',')['Text'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I check if after the pre-processing some reviews got completely delete because with a lot of noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([188001, 233938, 299605, 324249, 378643, 388831, 487863, 544869], dtype='int64')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_null_text_after_cleaning = df_text_cleaned[df_text_cleaned.isnull()].index\n",
    "idx_null_text_after_cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188001                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        v e r y g o o d v e r y g o o d v e r y g o o d v e r y g o o d\n",
       "233938    &#1056;&#1077;&#1096;&#1080;&#1083;&#1072; &#1079;&#1072;&#1082;&#1072;&#1079;&#1072;&#1090;&#1100; &#1101;&#1090;&#1080; &#1078;&#1077;&#1083;&#1072;&#1090;&#1080;&#1085;&#1082;&#1080;, &#1090;.&#1082;. &#1076;&#1086;&#1095;&#1082;&#1072; &#1087;&#1086;&#1096;&#1083;&#1072; &#1074; &#1096;&#1082;&#1086;&#1083;&#1091; &#1080; &#1090;&#1088;&#1077;&#1073;&#1091;&#1077;&#1090; &#1089;&#1083;&#1072;&#1076;&#1086;&#1089;&#1090;&#1080;. &#1054;&#1095;&#1077;&#1085;&#1100; &#1091;&#1076;&#1086;&#1073;&#1085;&#1072;&#1103; &#1091;&#1087;&#1072;&#1082;&#1086;&#1074;&#1082;&#1072;. &#1050;&#1072;&#1082; &#1088;&#1072;&#1079; &#1089;&#1090;&#1086;&#1083;&#1100;&#1082;&#1086; &#1082;&#1086;&#1085;&#1092;&#1077;&#1090;, &#1082;&#1072;&#1082; &#1080; &#1090;&#1088;&#1077;&#1073;&#1091;&#1077;&#1090;&#1089;&#1103;, &#1095;&#1090;&#1086;&#1073;&#1099; &#1089;&#1100;&#1077;&#1089;&#1090;&#1100; &#1080;&#1093; &#1079;&#1072; &#1087;&#1077;&#1088;&#1077;&#1084;&#1077;&#1085;&#1091;.\n",
       "299605                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        v e r y g o o d v e r y g o o d v e r y g o o d v e r y g o o d\n",
       "324249                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        v e r y g o o d v e r y g o o d v e r y g o o d v e r y g o o d\n",
       "378643                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     T H I S  C H O C O L A T E  I S  A D D I C T I O N  I  C A N 'T  S T O P  E A T I N G  I T T T T T\n",
       "388831                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        v e r y g o o d v e r y g o o d v e r y g o o d v e r y g o o d\n",
       "487863                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        v e r y g o o d v e r y g o o d v e r y g o o d v e r y g o o d\n",
       "544869                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        v e r y g o o d v e r y g o o d v e r y g o o d v e r y g o o d\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text[idx_null_text_after_cleaning]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I remove these reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_cleaned = df_text_cleaned[~df_text_cleaned.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I want to check if there are duplicates in the dataset. Since I am looking for similar reviews, I want to delete all the possible duplicates, in order to avoid useless computation later on.\n",
    "\n",
    "A trick I can use to figure out if there are duplicates is to use a Python Counter dictionary applied directly on the text. In this way, I will know if a phrase appear more than ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(df_text_cleaned.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(df_text_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_frequency = dict(sorted(counter.items(), key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n",
      "126\n",
      "51\n",
      "45\n",
      "42\n",
      "41\n",
      "38\n",
      "36\n",
      "35\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "review_to_print = 10\n",
    "for review, freq in text_frequency.items():\n",
    "    if review_to_print == 0:\n",
    "        break\n",
    "\n",
    "    print(freq)\n",
    "    review_to_print -= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates: 175480\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of duplicates: {sum(df_text_cleaned.duplicated())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are a lot of duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews before: 568446\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of reviews before: {df_text_cleaned.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of duplicates (175487) so I'll remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_cleaned.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews after: 392966\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of reviews after: {df_text_cleaned.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep track of the indices in the original dataframe by having a map from the new indices to the old ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_idx_new_to_old = dict(df_text_cleaned.reset_index()['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_cleaned.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Locality Sensitive Hashing Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the pre-processing, I reduced the dataset and vocabulary dimensions. This has a positive impact on the following computation!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can vectorize the dataset, by computing the TF-IDF vectors of each review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english') \n",
    "X_tfidf = vectorizer.fit_transform(df_text_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392966, 297509)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **L**ocality **S**ensitive **H**ashing (LSH) technique is based on the idea of mapping items onto buckets, with the goal of having *similar* items on the same bucket with high probabiliy. *Similar* in this case means having a cosine similarity over the threshold. A bucket can be seen as a set that belong to a hash table. \n",
    "\n",
    "Ideally we want to have similar elements in the same bucket and the non-similar ones on different buckets.\n",
    "\n",
    "\n",
    "Therefore, it is required a function (hash function $h$) that when applied to two vectors $x, y\\in {\\rm I\\!R}^d$, if they are similar ($sim(x, y) \\ge \\theta$), they will have with high probability the same value:\n",
    "$$\n",
    "P(h(x) = h(y)) \\ge P_1\n",
    "$$\n",
    "and vectors that are far apart ($sim(x, y) \\le c\\theta$) will have different value:\n",
    "$$\n",
    "P(h(x) = h(y)) \\le P_2\n",
    "$$\n",
    "with $P_2 < P_1$ and $c < 1$.\n",
    "\n",
    "In the case of **cosine similarity**, the function is:\n",
    "$$\n",
    "h_u(x) = sign(u \\cdot x)\n",
    "$$\n",
    "where $u \\in {\\rm I\\!R}^d$ is a random unit vector, which defines an hyperplane.\n",
    "\n",
    "The idea is to generate uniformly at random $m$ hyperplanes that divide the space, so that for a particular hyperplane, a point in this space ends up in one of the two regions which the plane separates. Thus, we have that the closest two points are, the more likely they will be on the same region for a random hyperplane. \n",
    "\n",
    "\n",
    "The probability that two vectors, as above, hash to the same value is:\n",
    "$$\n",
    "p = P(h(x) = h(y)) = 1 - \\frac{\\arccos(sim(x, y))} {\\pi}\n",
    "$$ \n",
    "\n",
    "Once the hash value (signature) of a vector is computed, we can divide it in $b$ bands, each one containing $r$ rows.\n",
    "\n",
    "Now, a pair of reviews is consider a candidate pair, so similar, if and only if they have the same values on all in at **least one band**.\n",
    "\n",
    "The probability that for at least one band all the hashes are equal for a pair of two reviews is:\n",
    "$$\n",
    "P_{sim} = 1 - (1 - p^r) ^ b\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Fixing the Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample uniformly at random the 1% of the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X_tfidf_threshold = train_test_split(X_tfidf, test_size=0.01, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3930, 297509)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf_threshold.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the average pairwise cosine similarity between the selected reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities_for_threshold = cosine_similarity(X_tfidf_threshold, X_tfidf_threshold, dense_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled average pairwaise cosine similarity: 0.01692\n",
      "39 x Sampled average pairwaise cosine similarity: 0.65969\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sampled average pairwaise cosine similarity: {np.mean(similarities_for_threshold):.5f}\")\n",
    "times = 39\n",
    "print(f\"{times} x Sampled average pairwaise cosine similarity: {np.mean(similarities_for_threshold) * times:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I select the threshold $\\theta$ equal to 0.65, therefore I consider two reviews to be **similar** when they have a cosine similarity greater than $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = 0.65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to show how changes the threshold when the $b$ and $r$ vary, I plotted $P_{sim}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.transforms as transforms\n",
    "\n",
    "\n",
    "def plot_lsh_curve(p, rows=5, bands=24):\n",
    "    x = np.linspace(0, 1, num=500)\n",
    "    P = lambda x: 1 - (1 - x**rows)**bands\n",
    "    \n",
    "    _, ax = plt.subplots(figsize=(8, 6), dpi=80)\n",
    "\n",
    "    ax.plot(x, P(x))\n",
    "    ax.axvline(p, linestyle=\"--\", color=\"r\", label=\"Threshold\")\n",
    "\n",
    "    trans = transforms.blended_transform_factory(\n",
    "        ax.get_xticklabels()[0].get_transform(), ax.transData)\n",
    "    ax.text(p + 0.005, -0.13, \"p\", color=\"red\", transform=trans, \n",
    "            ha=\"right\", va=\"center\", fontsize=12)\n",
    "\n",
    "    ax.fill_between(x, P(x), where=x < p,  step=\"pre\", alpha=0.5, label=\"False Positives\")\n",
    "    ax.fill_betweenx(P(x), x, p, where=P(x) > P(p), step=\"mid\", alpha=0.4, color=\"r\", label=\"False Negatives\")\n",
    "\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.ylabel('Probability Sharing Bucket', fontsize=12)\n",
    "    plt.xlabel('Similarity', fontsize=12)\n",
    "    ax.xaxis.set_label_coords(.5, -0.1)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7252311215194696"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 1 - np.arccos(theta) / np.pi\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph is such that:\n",
    "$$\n",
    "p \\sim \\left ( \\frac{1}{b} \\right )^{\\frac{1}{r}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680 0.8049356770309067\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = 17\n",
    "b = 40\n",
    "\n",
    "print(r * b, (1/b) ** (1/r))\n",
    "plot_lsh_curve(p, r, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some trials I chose those values for $r$ and $b$, as it computationally feasible and it does not include too many false positives in the LSH buckets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Compute Signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashTable:\n",
    "    def __init__(self, signature_size: int, inp_dimensions: int):\n",
    "        self.signature_size = signature_size\n",
    "        self.projections = np.random.randn(self.signature_size, inp_dimensions)\n",
    "    \n",
    "    def generate_hash(self, inp_vector: Union[ scipy.sparse.csr.csr_matrix, np.ndarray ] ):\n",
    "        # If the dot product is greater than 0, we have a 1, otherwise a 0.\n",
    "        one_hot_signature = (inp_vector @ self.projections.T > 0).astype(np.uint8)\n",
    "        return [''.join(signature.astype(str)) for signature in one_hot_signature]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 17\n",
    "bands = 40\n",
    "\n",
    "signature_size = rows * bands\n",
    "inp_dimensions = X_tfidf.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_hash = HashTable(signature_size, inp_dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return Signature: 2m 30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "signatures = cosine_hash.generate_hash(X_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I save the signatures via `pickle`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    with open('sig_17_40.pkl', 'wb') as f:\n",
    "        pickle.dump(signatures, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sig_17_40.pkl', 'rb') as f:\n",
    "    signatures = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I split the original dataset into training and test sets at the beginning to store their indices, so I will not lose the reference after the analysis. I consider the 0.7% of the reviews as test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_train, df_text_test = train_test_split(df_text_cleaned, test_size=0.007, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idxs = df_text_train.index.sort_values()\n",
    "test_idxs = df_text_test.index.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf_train = X_tfidf[train_idxs]\n",
    "X_tfidf_test = X_tfidf[test_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dimension: 390215\n",
      "Test dimension: 2751\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training dimension: {df_text_train.shape[0]}\")\n",
    "print(f\"Test dimension: {df_text_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 LSH Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried to consider the efficient ways to compute the buckets for LSH. The first and intuitive approach is of course using Python sets to store review indices for a given combination of bits. However, when the number of rows to be consider is small (rows < 8), Python sets become quite inefficient in storing indices and in particular in the later computation of the B set for the test reviews. The reason why is that there are so many reviews sharing that given number of bits, thus they will be part of the same set. \n",
    "\n",
    "Therefore, I decided to implement also another approach that is base on NumPy arrays. These arrays are very efficient in accessing their elements and for matrix calculations. When the number of rows is small (rows < 8), it is convenient to use this method, as the the number of similar reviews is pretty high, so the matrix will be almost dense. In this case, the array will have dimension ( len(signatures) ) and initialized with zeros; in such a way that, for a given sequence of bits of a particular review, there will be a 1 in the position of that review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSH:\n",
    "    def __init__(self, bands: int, rows: int, matrix_form: bool=False):\n",
    "        self.bands = bands\n",
    "        self.rows = rows\n",
    "        self.matrix_form = matrix_form\n",
    "\n",
    "        # The dictionaries will contain numpy arrays\n",
    "        if matrix_form:\n",
    "            self.dictionaries = [defaultdict(np.ndarray) for _ in range(bands)]\n",
    "            self.bits_combinations = [\"\".join(bits) for bits in itertools.product(['0', '1'], repeat=self.rows)] \n",
    "        \n",
    "        else: # The dictionaries will sets\n",
    "            self.dictionaries = [defaultdict(set) for _ in range(bands)]\n",
    "        \n",
    "\n",
    "    def compute_dictionaries(self, signatures: Union[ List[str], np.ndarray ]):\n",
    "        # Initialize numpy arrays\n",
    "        if self.matrix_form:\n",
    "            for d in self.dictionaries:\n",
    "                for bits in self.bits_combinations:\n",
    "                    d[bits] = np.zeros(len(signatures), dtype=np.uint8)\n",
    "\n",
    "        # For every signature\n",
    "        for idx, sig in enumerate(signatures):\n",
    "            # For every bucket (dictionary)\n",
    "            for i in range(self.bands):\n",
    "                # Get 'self.rows' bits from the signature and hash them\n",
    "                bits_in_band = sig[i * self.rows : self.rows * (i + 1)]\n",
    "\n",
    "                if self.matrix_form:\n",
    "                    self.dictionaries[i][bits_in_band][idx] = 1\n",
    "\n",
    "                else:\n",
    "                    # Add the signature index (equivalently, the review index) to the i-th dictionary\n",
    "                    self.dictionaries[i][bits_in_band].add(idx)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsh = LSH(bands, rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_signatures = np.array(signatures)\n",
    "# Get training signatures\n",
    "train_signatures = np_signatures[train_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will compute the buckets for the training signatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_buckets = time.time()\n",
    "lsh.compute_dictionaries(train_signatures)\n",
    "end_buckets = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time required to compute buckets: 17.945s\n"
     ]
    }
   ],
   "source": [
    "print(f\"Time required to compute buckets: {end_buckets - start_buckets:.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dictionaries:\n",
    "\n",
    "    with open('dict_17_40.pkl', 'wb') as f:\n",
    "        pickle.dump(lsh.dictionaries, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dict_17_40.pkl', 'rb') as f:\n",
    "    lsh.dictionaries = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of reviews in one band: 3.2961523841702918\n"
     ]
    }
   ],
   "source": [
    "d = lsh.dictionaries[0]\n",
    "num_values_in_dict = sum(len(v) for k, v in d.items())\n",
    "print(\"Average number of reviews in one band:\", num_values_in_dict / len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = 0.65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Exact Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exact cosine similarity for computing the set A can be efficiently performed by batching the reviews. Once a batch is computed, it is stacked with the previous ones. Moreover, even if the matrix is dense it is memory efficient, since I will only store booleans, resulting from `reviews_similarity > theta`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_exact_stacked_similarity(\n",
    "    X_tfidf_test: scipy.sparse.csr.csr_matrix, \n",
    "    X_tfidf_train: scipy.sparse.csr.csr_matrix, \n",
    "    theta: float,\n",
    "    batch_size: int=250\n",
    ") -> Dict[int, set]:\n",
    "    \n",
    "    # First batch\n",
    "    reviews_similarity = cosine_similarity(X_tfidf_test[:batch_size], X_tfidf_train, dense_output=True)\n",
    "    stacked_similarities = reviews_similarity > theta\n",
    "\n",
    "    # Remaining batches\n",
    "    for i in range(batch_size, X_tfidf_test.shape[0], batch_size):\n",
    "        test_reviews = X_tfidf_test[i : i + batch_size]\n",
    "\n",
    "        # Compute cosine\n",
    "        reviews_similarity = cosine_similarity(test_reviews, X_tfidf_train, dense_output=True)\n",
    "        # Stack to the previous batches\n",
    "        stacked_similarities = np.vstack([stacked_similarities, reviews_similarity > theta])\n",
    "\n",
    "    return stacked_similarities\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_exact_similarity(\n",
    "    stacked_similarities: np.ndarray, \n",
    "    test_idxs: np.ndarray,\n",
    "    train_idxs: np.ndarray,\n",
    ") -> Dict[int, set]:\n",
    "    \n",
    "    exact_similarity_A = defaultdict(set)\n",
    "\n",
    "    # 'similar_over_threshold' is a numpy array of boolean.\n",
    "    # It is True in the indices for which the cosine resulted greater than theta.\n",
    "    for review_idx, similar_over_threshold in enumerate(stacked_similarities):\n",
    "        # Map to the indices in the original dataset\n",
    "        test_review_original_idx = test_idxs[review_idx]\n",
    "        \n",
    "        # Get indices of the similar reviews in the training set\n",
    "        similar_in_train_idxs = np.argwhere(similar_over_threshold).squeeze()\n",
    "        \n",
    "        if similar_in_train_idxs.size > 1:\n",
    "            # Map to the indices in the original dataset\n",
    "            train_reviews_original_idxs = map(lambda idx: train_idxs[idx], similar_in_train_idxs)\n",
    "            exact_similarity_A[test_review_original_idx] = set(train_reviews_original_idxs)\n",
    "        elif similar_in_train_idxs.size == 1:\n",
    "            exact_similarity_A[test_review_original_idx] = {train_idxs[similar_in_train_idxs]}\n",
    "        else:\n",
    "            exact_similarity_A[test_review_original_idx] = set()\n",
    "\n",
    "    return exact_similarity_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_A = time.time()\n",
    "stacked_similarities = compute_exact_stacked_similarity(X_tfidf_test, X_tfidf_train, theta)\n",
    "exact_similarity_A = compute_exact_similarity(stacked_similarities, test_idxs, train_idxs)\n",
    "end_A = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time required to compute A with the exact cosine similarity: 30.362s\n"
     ]
    }
   ],
   "source": [
    "print(f\"Time required to compute A with the exact cosine similarity: {end_A - start_A:.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023 {2069}\n",
      "7790 {371878, 556, 160524, 252630, 48503}\n",
      "8449 {66155}\n",
      "11136 {196533}\n",
      "12070 {259490}\n",
      "15158 {67459, 71497, 220909, 233652, 15220}\n",
      "16188 {197408}\n",
      "17683 {297144, 89733, 151886}\n",
      "20306 {80228, 38660, 312073, 8013, 185748, 52062}\n",
      "21925 {9813, 97686}\n",
      "22932 {123302, 22974}\n",
      "24568 {85538}\n",
      "24924 {121848, 98303}\n",
      "28680 {205026, 238530, 238500, 28777, 153673, 28844, 153741, 238621, 153688, 28826, 153788, 28701, 28830, 28798}\n",
      "28746 {260152}\n",
      "32721 {374510, 91505, 123666, 362615, 29144, 29566}\n",
      "36924 {306497, 111979}\n",
      "38631 {11641, 98700}\n",
      "39364 {124400, 103057, 171525, 147169}\n",
      "39806 {232768, 39789, 39790, 39791, 155380, 39797, 203125, 39643, 39613, 39615}\n",
      "48487 {97891}\n",
      "48878 {281260}\n",
      "50381 {70612}\n",
      "52099 {208919}\n",
      "55053 {3842}\n",
      "55258 {55217, 55257, 55205}\n",
      "57206 {214305}\n",
      "57246 {57257}\n",
      "58979 {238972, 250415}\n",
      "60216 {312352, 115106, 294255, 271759, 312310, 95670, 335702, 381306, 312350}\n",
      "60547 {237528}\n",
      "61680 {277118}\n",
      "65240 {377395}\n",
      "65842 {95185}\n",
      "69869 {69863}\n",
      "73197 {291130}\n",
      "79375 {156223}\n",
      "83154 {303445}\n",
      "84054 {172986, 170805, 243266}\n",
      "100959 {132036, 35983}\n",
      "103384 {103408, 211453}\n",
      "105280 {362049}\n",
      "106816 {209675}\n",
      "109218 {109274}\n",
      "110081 {295833}\n",
      "112095 {174256, 333004, 94358, 324143}\n",
      "112264 {143931, 234338, 121547}\n",
      "126522 {126427}\n",
      "128322 {172064, 205789, 22813}\n",
      "129547 {106649}\n",
      "134992 {97258, 158532, 97470}\n",
      "136996 {311366}\n",
      "139193 {220996, 139207, 139242, 139248, 11122, 130035, 287034}\n",
      "141469 {187434, 316947}\n",
      "144145 {367600}\n",
      "146597 {125225}\n",
      "148896 {234726}\n",
      "154597 {332648, 56003}\n",
      "161924 {298670}\n",
      "165017 {27888, 28036, 27844, 390742}\n",
      "166143 {368317, 168526}\n",
      "177690 {350520}\n",
      "178475 {178440}\n",
      "184415 {332793}\n",
      "186442 {123778, 18503, 172427, 186131, 42995, 186134, 263576}\n",
      "186700 {1555, 269939}\n",
      "192100 {283127, 240511, 225175}\n",
      "192466 {329951}\n",
      "192575 {192625}\n",
      "198358 {130308, 130309, 130311, 130314, 130321, 130323, 130328, 130335, 130344, 130345, 130353, 130354, 130359, 130282, 130285, 130286, 130291, 130301, 130302, 130303}\n",
      "199913 {239888, 66959}\n",
      "208275 {235144, 260690, 260694}\n",
      "208479 {208481}\n",
      "209378 {241671, 241806, 68498, 209434, 362781, 133154, 209449, 5034, 5036, 209455, 209470, 209471, 209477, 209352, 337224, 337226, 209231, 209488, 209245, 209502, 348126, 209505, 209508, 209509, 241638, 209255, 209383, 93929, 209264, 241649, 209394, 209395, 209399, 351993}\n",
      "209866 {209874}\n",
      "218326 {257098}\n",
      "222695 {195410, 371972, 374751}\n",
      "224935 {274676}\n",
      "228785 {22720}\n",
      "230531 {130191}\n",
      "233913 {8986}\n",
      "241195 {196186}\n",
      "242527 {358151}\n",
      "246024 {246022}\n",
      "249411 {301570, 87402, 360203, 168566, 301564}\n",
      "252303 {376279}\n",
      "254363 {102354}\n",
      "265826 {86184}\n",
      "266387 {316316}\n",
      "273620 {181044, 9342}\n",
      "274380 {299702, 51999}\n",
      "275900 {302944}\n",
      "278178 {32744, 23474}\n",
      "280843 {382890, 128946, 258093}\n",
      "295286 {291826}\n",
      "306055 {333444, 177788}\n",
      "311787 {354688}\n",
      "312765 {179778, 105909, 320903}\n",
      "314869 {69952, 52522, 52535}\n",
      "322704 {271134}\n",
      "326492 {381850}\n",
      "331278 {366675, 285942, 51414, 285934}\n",
      "336638 {209165}\n",
      "340040 {381911}\n",
      "345423 {185586}\n",
      "345481 {362049, 164321, 201198, 366808}\n",
      "349677 {21763, 174787, 92332, 14572, 101677, 30527}\n",
      "349912 {327168, 240651, 101392, 141971, 299031, 93850, 115867, 283937, 199076, 384299, 216890, 321339, 302916, 40142, 374098, 143315, 147796, 285271, 70743, 105315, 33133, 383608}\n",
      "350293 {54542}\n",
      "351163 {351161}\n",
      "355557 {324304, 308050, 327309, 185423}\n",
      "357426 {357429}\n",
      "357680 {211194}\n",
      "361767 {370337, 110406, 361768, 330506, 269680, 361778, 284469, 337304, 330492, 130399}\n",
      "362519 {5482}\n",
      "364408 {115866, 364444, 202023, 115754, 115884, 311597, 115761, 154298, 115784, 115788, 181713, 364369, 364376, 38878, 200292, 181733, 181735, 12776, 38904, 364410, 189180}\n",
      "365062 {340585, 340524, 340589}\n",
      "371960 {144728}\n",
      "376119 {337795}\n",
      "377897 {378202}\n",
      "381116 {3555}\n",
      "382707 {312643}\n",
      "384097 {52465}\n",
      "385454 {360525}\n",
      "385614 {208773}\n",
      "389809 {389813}\n",
      "389870 {389676, 390358}\n",
      "392409 {196501}\n",
      "392418 {358020, 358021, 238502, 289469, 28777, 369161, 28651, 81867, 153741, 238676, 42390, 372310, 238520, 345818, 28861}\n"
     ]
    }
   ],
   "source": [
    "non_empty = 0\n",
    "for idx, s in exact_similarity_A.items():\n",
    "    if len(s) != 0:\n",
    "        print(idx, s)\n",
    "        non_empty += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04689203925845147"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_empty / len(test_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that value of theta, only 4% of the test reviews have a similar in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save A:\n",
    "\n",
    "    with open('A_065.pkl', 'wb') as f:\n",
    "        pickle.dump(exact_similarity_A, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('A_65.pkl', 'rb') as f:\n",
    "    exact_similarity_A = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the exact computation of the similarities is correct for some reviews: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good grapefruit juice fact best grapefruit juice ever take long pack however product buy cost\n",
      "grapefruit flavor sparkling water simply delicious refreshing really taste like grapefruit juice better also orange mango good favorite grapefruit\n"
     ]
    }
   ],
   "source": [
    "# This two are considered similar\n",
    "print(df_text_cleaned[121848])\n",
    "print(df_text_cleaned[98303])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed they are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buy coffee enjoy great strong tasting coffee\n",
      "love coffee add small amount regular coffee really make great tasting cup coffee\n"
     ]
    }
   ],
   "source": [
    "print(df_text_cleaned[306497])\n",
    "print(df_text_cleaned[111979])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 LSH Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lsh_similarity(\n",
    "    lsh: LSH,\n",
    "    test_signatures: Union[ List[str], np.ndarray ], \n",
    "    test_idxs: np.ndarray, \n",
    "    rows: int,\n",
    "    bands: int,\n",
    "    \n",
    ") -> Dict[int, set]:\n",
    "\n",
    "    lsh_similarity_B = defaultdict(set)\n",
    "    for review_idx, sig in enumerate(test_signatures):\n",
    "        # Map to the indices in the original dataset\n",
    "        test_review_original_idx = test_idxs[review_idx]\n",
    "        \n",
    "        for i in range(bands):\n",
    "            bits_in_band = sig[i * rows : rows * (i + 1)]              # The training indices are the correct ones wrt the original dataset\n",
    "            lsh_similarity_B[test_review_original_idx] = lsh_similarity_B[test_review_original_idx].union(lsh.dictionaries[i][bits_in_band])\n",
    "\n",
    "    return lsh_similarity_B\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_signatures = np_signatures[test_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_B = time.time()\n",
    "lsh_similarity_B = compute_lsh_similarity(lsh, test_signatures, test_idxs, rows, bands)\n",
    "end_B = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time required to compute B with the LSH method: 0.364s\n"
     ]
    }
   ],
   "source": [
    "print(f\"Time required to compute B with the LSH method: {end_B - start_B:.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Comparisons between A and B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is possible to compare the sets obtained from the exact compution A and the ones from the LSH method B. I will average the jaccard similarities between the sets of each test review. I also consider the case 'is_subset' to count how many elements of a set in A are in B. In this way, I am computing the number of reviews that are considered similar by the LSH approach and that are indeed similar. Therefore, it is a metric for the **recall**, as it counts the number of correctly predicted reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccards = {}\n",
    "is_subset = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for review_idx in test_idxs:\n",
    "    union = exact_similarity_A[review_idx] | lsh_similarity_B[review_idx]\n",
    "    intersection = exact_similarity_A[review_idx] & lsh_similarity_B[review_idx]\n",
    "\n",
    "    # When the union is 0, the two sets are empy therefore the jaccard is 1\n",
    "    jaccards[review_idx] = 1 if len(union) == 0 else len(intersection) / len(union)\n",
    "    \n",
    "    if len(exact_similarity_A[review_idx]) == 0:\n",
    "        # If also the lsh set is empty, the is_subset metric is 1, otherwise 0\n",
    "        is_subset[review_idx] = 1 if len(lsh_similarity_B[review_idx]) == 0 else 0\n",
    "    else:\n",
    "        is_subset[review_idx] = len(intersection) / len(exact_similarity_A[review_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard mean: 1.8451988847617938e-06\n"
     ]
    }
   ],
   "source": [
    "print(f\"Jaccard mean: {np.mean(list(jaccards.values()))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall mean: 2.4233612019871563e-05\n"
     ]
    }
   ],
   "source": [
    "print(f\"Recall mean: {np.mean(list(is_subset.values()))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that A and B are not similar as the Jaccard is approximately 0. The number is so small, also because I have removed all the duplicates from the dataset, thereby the number of possible similars decreases consistently. \n",
    "\n",
    "Even though I tried many configurations for b and r, the results did not change much. This is one of the best configuration I found.\n",
    "\n",
    "When I considered a small number of rows (r= 2,..7) to increase recall (against precision), the computation of B took so long that either did not fit in main memory or A was much faster to compute. For this reason I thought to the matrix approach using NumPy. But of course when the number of rows increases, the matrix becomes exponentially large and so it is not feasible anymore. I did not tried to make it sparse thanks to Scipy. I avoid sparsity in this case because it would be more difficult to keep the reference with the indices to the original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSH:\n",
    "\n",
    "- Computation of signatures: 2m 30s\n",
    "- Computation of buckets: 18s\n",
    "- Computation of B: 0.3s\n",
    "\n",
    "Exact:\n",
    "\n",
    "- Computation of A: 30s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we exclude the pre-processing of the signatures, the LSH method is faster (**18.3s** < **30s**) than the exact computation with this configuration of $m = bands \\cdot rows = 40 \\cdot 17 = 680$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it follows the NumPy approach, but I did not test it so much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the dictionaries are in matrix form `LSH(bands, rows, matrix_form=True)`, we store NumPy arrays instead of Python sets. In this case, for a given test review, I can see which training reviews fall in its bucket by summing up, columm by column, all the arrays associated with this test review, i.e., the arrays at index `lsh.dictionaries[i][bits_in_band]`. I remember that each bucket array only contains binary values, where there is a 1 in the position of the training review that resides in that bucket. Therefore, when I consider a test review, I am interested in the buckets it should fall into, by considering 'rows' bits at a time of its signature. So, there will be 'bands' arrays for a given test review. \n",
    "\n",
    "If I sum up all these arrays I will obtain an array that has non-zero values in the positions of the training reviews that appear in all those arrays. In other words, the sum expresses the union of sets.\n",
    "\n",
    "The advantage of this is that summation of NumPy arrays is really efficient, more than union set, if the matrix is dense or partially dense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_similarities = np.zeros((len(test_idxs), len(train_idxs)), dtype=np.uint32)\n",
    "\n",
    "for review_idx, sig in enumerate(test_signatures):\n",
    "    # Map to the indices in the original dataset\n",
    "    test_review_original_idx = test_idxs[review_idx]\n",
    "    \n",
    "    for i in range(bands):\n",
    "        bits_in_band = sig[i * rows : rows * (i + 1)]\n",
    "        test_similarities[review_idx] = np.sum([test_similarities[review_idx], lsh.dictionaries[i][bits_in_band]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_similarities = compute_exact_stacked_similarity(X_tfidf_test, X_tfidf_train, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`logical_and` and `logical_or` convert in booleans the values of the matrices. Thus, all the non-zero value will be True and the zero values False. Then, if you sum up the cells that give True for the intersection, we will get the cardinality of the intersection, so the numerator of the Jaccard. On the other hand, the sum on the union will result into the denominator of the Jaccard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = np.logical_and(test_similarities, stacked_similarities) \n",
    "union = np.logical_or(test_similarities, stacked_similarities)\n",
    "\n",
    "print(f\"Jaccard mean: {intersection.sum() / float(union.sum())}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('DL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf37a2529baf03c803266b8d55d553bda8f92a60c47b8d9f7bdcfc02cbd55fef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
